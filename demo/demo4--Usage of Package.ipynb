{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preamble  here, add paths and import relevant modules\n",
    "import os, sys, numpy as np, sklearn\n",
    "from numpy.random import randn\n",
    "sys.path.append('/'.join(os.getcwd().split('/')[:-1]))\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4 -- Usage of GraphAlgorithms Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've done some examples, here is a detailed description for the usage of the actual package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main interface with the user is suppose to go through the classifier class `LaplacianClustering`. Basically all graph construction, prediction and parameter setting can be done via this class only. The name `LaplacianClustering` stems from the fact that all algorithms are some form of clustering, and the Graph Laplacian is used. Future versions will contain non-Laplacian based graph methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a classifier, setting some parameters in the constructor\n",
    "from graph_cluster import LaplacianClustering\n",
    "clf = LaplacianClustering(scheme_type = 'MBO_fidelity', 'eta':2, 'dt':.6)\n",
    "\n",
    "# load the data into the classifier, ground_truth if you have any\n",
    "raw_data = randn(50,2)\n",
    "clf.load_data(raw_data = raw_data)\n",
    "\n",
    "# build the graph\n",
    "clf.build_graph(affinity = 'rbf', Neig = 3, gamma = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, all parameters could be defined and changed using the constructor and the `set_parameters` function, but `load_data` and `set_graph_parameters` are specialized function for setting the data and graph_params fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is stored in `clf.graph`, which is a `BuildGraph()` instance. Changing the `raw_data` automatically deletes the graph, while changing parameters in `clf.graph` automatically triggers a recomputation of the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate random initial condition\n",
    "clf.generate_initial_value()\n",
    "# load a ground truth\n",
    "clf.load_raw_data(ground_truth = np.ones(50).astype(int))\n",
    "# generate random fidelity\n",
    "clf.generate_random_fidelity(percent = .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class also has built in methods for generating initial values, and fidelity points. It can also compute the misclassification rate for your result. Of course, you need to load in the ground_truth for the latter two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do a prediction, just call the `fit_predict` method. The name is to be consistent with the `sklearn` notation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nice thing about modularizing all the code is that when doing multiple tests, different parameters for the scheme can be changed without recomputing everything again, unless the parameter changed affects the underlying data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For example, after I'm done with MBO fidelity in the example above, to change the scheme to \n",
    "# 'GL_fidelity', simple switch the 'scheme_type' attribute:\n",
    "clf.set_parameters(scheme_type = 'GL_fidelity') #that's all!\n",
    "\n",
    "# Or if there's any change to the graph parameters\n",
    "clf.set_graph_params(neighbor_type = 'connectivity', n_neighbors = 10)\n",
    "#The graph Laplacian is automatically recomputed everytime this function is triggered. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class is designed for multiple tests with mimimal effort. Hence parameters are updated lazily, i.e., if it's not specified in the `set_parameters` argument, it stays(mostly) the same. To clear the parameters, use the `clear()` method supplied by the `Parameter` class. If any crucial parameter is missing, the code should raise an error or print a warning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this is a first version of the package, and many improvements + new functionalities are expected to be added. Below are some key references to the entire package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Here are some refs I've listed\n",
    "\n",
    "- Bertozzi, Andrea L., and Arjuna Flenner. \"Diffuse interface models on graphs for classification of high dimensional data.\" *Multiscale Modeling & Simulation* 10.3 (2012): 1090-1118. <a href=\"http://epubs.siam.org/doi/pdf/10.1137/11083109X\" target=\"_blank\"> link</a>\n",
    "\n",
    "- Merkurjev, Ekaterina, Justin Sunu, and Andrea L. Bertozzi. \"Graph MBO method for multiclass segmentation of hyperspectral stand-off detection video.\" *Image Processing (ICIP), 2014 IEEE International Conference on.* IEEE, 2014. <a href=\"http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7025138\" target=\"_blank\"> link</a>\n",
    "\n",
    "- Hu, Huiyi, et al. \"A method based on total variation for network modularity optimization using the MBO scheme.\" *SIAM Journal on Applied Mathematics* 73.6 (2013): 2224-2246. <a href=\"http://epubs.siam.org/doi/pdf/10.1137/130917387\" target=\"_blank\"> link</a>\n",
    "\n",
    "- Hu, Huiyi, et al. \"A method based on total variation for network modularity optimization using the MBO scheme.\" *SIAM Journal on Applied Mathematics* 73.6 (2013): 2224-2246. <a href=\"http://www.math.ucla.edu/~bertozzi/papers/EMMCVPRfinal.pdf\" target=\"_blank\"> link</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
